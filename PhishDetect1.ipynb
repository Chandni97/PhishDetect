{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>1.71</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>1</th>\n",
       "      <th>0.54</th>\n",
       "      <th>0.7</th>\n",
       "      <th>1.1</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>1.2</th>\n",
       "      <th>0.10</th>\n",
       "      <th>280</th>\n",
       "      <th>0.11</th>\n",
       "      <th>0.12</th>\n",
       "      <th>0.13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>170.433333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>377.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>328.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>267.833333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>340.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  1.71  0.5  0.6     1  0.54   0.7  1.1  0.8  0.9  \\\n",
       "0  0    0    0    0    0  0.13    1    0  1.00  0.96  0.71    1    0    0   \n",
       "1  0    0    0    0    0  9.26    1    0  0.75  0.68  0.22    0    0    0   \n",
       "2  0    0    0    0    0  7.79    1    0  0.00  0.09  1.00    0    0    0   \n",
       "3  0    0    0    0    0  4.04    1    0  0.00  0.08  0.57    0    0    0   \n",
       "4  0    0    0    0    0  4.06    1    0  0.93  0.44  0.72    0    0    0   \n",
       "\n",
       "   1.2  0.10         280  0.11  0.12  0.13  \n",
       "0    1     0  170.433333     0     0     0  \n",
       "1    1     0  377.466667     0     0     0  \n",
       "2    1     0  328.733333     0     0     0  \n",
       "3    1     0  267.833333     0     0     0  \n",
       "4    1     0  340.933333     0     0     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "from random import sample  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn import tree  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.cross_validation import cross_val_score  \n",
    "from sklearn import metrics  \n",
    "from IPython.display import Image  \n",
    "import sys\n",
    "import types\n",
    "import pandas as pd\n",
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "client_1bb9852030454733b48fb2131469bdfe = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='',\n",
    "    ibm_auth_endpoint=\"\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='')\n",
    "\n",
    "body = client_1bb9852030454733b48fb2131469bdfe.get_object(Bucket='',Key='')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df = pd.read_csv(body)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding column names and standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438.333333333\n"
     ]
    }
   ],
   "source": [
    "#adding column names\n",
    "headers = ['url having ip', 'sslfinal_state', 'url_short', 'having_at_symbol', 'doubleslash', 'domain_registation_length'\n",
    "                   , 'favicon', 'https_token', 'request_url', 'url_of_anchor', 'links_in_tags', 'sfh', 'submitting_to_email',\n",
    "                   'abnormal url', 'redirect', 'iframe', 'age_of_domain', 'web_traffic', 'statistical_report', 'target']\n",
    "df.columns = headers\n",
    "\n",
    "#standardizing data\n",
    "print(df['age_of_domain'].max())\n",
    "df['age_of_domain'] = df['age_of_domain']/df['age_of_domain'].max()\n",
    "df['age_of_domain'] = round(df['age_of_domain'],2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.312, 'web_traffic'), (0.21049999999999999, 'sslfinal_state'), (0.1525, 'age_of_domain'), (0.0969, 'domain_registation_length'), (0.089399999999999993, 'links_in_tags'), (0.071300000000000002, 'redirect'), (0.045400000000000003, 'url_of_anchor'), (0.0070000000000000001, 'favicon'), (0.0068999999999999999, 'sfh'), (0.0038999999999999998, 'request_url'), (0.002, 'abnormal url'), (0.0014, 'url_short'), (0.00080000000000000004, 'having_at_symbol'), (0.0, 'url having ip'), (0.0, 'submitting_to_email'), (0.0, 'statistical_report'), (0.0, 'iframe'), (0.0, 'https_token'), (0.0, 'doubleslash')]\n"
     ]
    }
   ],
   "source": [
    "train, test, validate = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))]) \n",
    "y_train = train['target']  \n",
    "x_train = train.drop(['target'], axis=1)  \n",
    "y_test = test['target']  \n",
    "x_test = test.drop(['target'], axis=1)  \n",
    "y_validate = validate['target']  \n",
    "x_validate = validate.drop(['target'], axis=1)\n",
    "rf = RandomForestClassifier()  \n",
    "rf.fit(x_train, y_train)  \n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), x_train), reverse=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset with reduced feature set (top 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = x_train.columns.tolist()\n",
    "top_vars = ['web_traffic', 'sslfinal_state', 'age_of_domain', 'url_of_anchor', 'domain_registation_length', 'redirect', 'links_in_tags']\n",
    "bottom_vars = [cols for cols in all_vars if cols not in top_vars]\n",
    "x_train    = x_train.drop(bottom_vars, axis=1)  \n",
    "x_test     = x_test.drop(bottom_vars, axis=1)  \n",
    "x_validate = x_validate.drop(bottom_vars, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training different machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = LogisticRegression()  \n",
    "\n",
    "logit_model = logit_model.fit(x_train, y_train)  \n",
    "\n",
    "logit_model.score(x_train, y_train)  \n",
    "\n",
    "predicted = pd.DataFrame(logit_model.predict(x_test))  \n",
    "\n",
    "probs = pd.DataFrame(logit_model.predict_proba(x_test))  \n",
    "\n",
    "logit_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "logit_roc_auc = metrics.roc_auc_score(y_test, probs[1])  \n",
    "logit_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "logit_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "logit_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "logit_recall = metrics.recall_score(y_test, predicted, pos_label=1)  \n",
    "logit_f1 = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "logit_cv_scores = cross_val_score(LogisticRegression(), x_test, y_test, scoring='precision', cv=10)  \n",
    "logit_cv_mean = np.mean(logit_cv_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate with a max depth of 3\n",
    "tree_model = tree.DecisionTreeClassifier(max_depth=3)  \n",
    "# Fit a decision tree\n",
    "tree_model = tree_model.fit(x_train, y_train)  \n",
    "# Training accuracy\n",
    "tree_model.score(x_train, y_train)\n",
    "\n",
    "# Predictions/probs on the test dataset\n",
    "predicted = pd.DataFrame(tree_model.predict(x_test))  \n",
    "probs = pd.DataFrame(tree_model.predict_proba(x_test))\n",
    "\n",
    "# Store metrics\n",
    "tree_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "tree_roc_auc = metrics.roc_auc_score(y_test, probs[1])  \n",
    "tree_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "tree_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "tree_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "tree_recall = metrics.recall_score(y_test, predicted, pos_label=1)  \n",
    "tree_f1 = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# evaluate the model using 10-fold cross-validation\n",
    "tree_cv_scores = cross_val_score(tree.DecisionTreeClassifier(max_depth=3), x_test, y_test, scoring='precision', cv=10)\n",
    "tree_cv_mean = np.mean(tree_cv_scores)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "rf = RandomForestClassifier()  \n",
    "# Fit\n",
    "rf_model = rf.fit(x_train, y_train)  \n",
    "# training accuracy 99.74%\n",
    "rf_model.score(x_train, y_train)\n",
    "\n",
    "# Predictions/probs on the test dataset\n",
    "predicted = pd.DataFrame(rf_model.predict(x_test))  \n",
    "probs = pd.DataFrame(rf_model.predict_proba(x_test))\n",
    "\n",
    "# Store metrics\n",
    "rf_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "rf_roc_auc = metrics.roc_auc_score(y_test, probs[1])  \n",
    "rf_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "rf_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "rf_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "rf_recall = metrics.recall_score(y_test, predicted, pos_label=1)  \n",
    "rf_f1 = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "rf_cv_scores = cross_val_score(RandomForestClassifier(), x_test, y_test, scoring='precision', cv=10)  \n",
    "rf_cv_mean = np.mean(rf_cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "svm_model = SVC(probability=True)  \n",
    "# Fit\n",
    "svm_model = svm_model.fit(x_train, y_train)  \n",
    "# Accuracy\n",
    "svm_model.score(x_train, y_train)\n",
    "\n",
    "# Predictions/probs on the test dataset\n",
    "predicted = pd.DataFrame(svm_model.predict(x_test))  \n",
    "probs = pd.DataFrame(svm_model.predict_proba(x_test))\n",
    "\n",
    "# Store metrics\n",
    "svm_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "svm_roc_auc = metrics.roc_auc_score(y_test, probs[1])  \n",
    "svm_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "svm_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "svm_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "svm_recall = metrics.recall_score(y_test, predicted, pos_label=1)  \n",
    "svm_f1 = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "svm_cv_scores = cross_val_score(SVC(probability=True), x_test, y_test, scoring='precision', cv=10)  \n",
    "svm_cv_mean = np.mean(svm_cv_scores)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate learning model (k = 3)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)  \n",
    "# fit the model\n",
    "knn_model.fit(x_train, y_train)  \n",
    "# Accuracy\n",
    "knn_model.score(x_train, y_train)\n",
    "\n",
    "# Predictions/probs on the test dataset\n",
    "predicted = pd.DataFrame(knn_model.predict(x_test))  \n",
    "probs = pd.DataFrame(knn_model.predict_proba(x_test))\n",
    "\n",
    "# Store metrics\n",
    "knn_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "knn_roc_auc = metrics.roc_auc_score(y_test, probs[1])  \n",
    "knn_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "knn_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "knn_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "knn_recall = metrics.recall_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "knn_f1 = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "knn_cv_scores = cross_val_score(KNeighborsClassifier(n_neighbors=3), x_test, y_test, scoring='precision', cv=10)  \n",
    "knn_cv_mean = np.mean(knn_cv_scores)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "bayes_model = GaussianNB()  \n",
    "# Fit the model\n",
    "bayes_model.fit(x_train, y_train)  \n",
    "# Accuracy\n",
    "bayes_model.score(x_train, y_train)\n",
    "\n",
    "# Predictions/probs on the test dataset\n",
    "predicted = pd.DataFrame(bayes_model.predict(x_test))  \n",
    "probs = pd.DataFrame(bayes_model.predict_proba(x_test))\n",
    "\n",
    "# Store metrics\n",
    "bayes_accuracy = metrics.accuracy_score(y_test, predicted)  \n",
    "bayes_roc_auc = metrics.roc_auc_score(y_test, probs[1])  \n",
    "bayes_confus_matrix = metrics.confusion_matrix(y_test, predicted)  \n",
    "bayes_classification_report = metrics.classification_report(y_test, predicted)  \n",
    "bayes_precision = metrics.precision_score(y_test, predicted, pos_label=1)  \n",
    "bayes_recall = metrics.recall_score(y_test, predicted, pos_label=1)  \n",
    "bayes_f1 = metrics.f1_score(y_test, predicted, pos_label=1)\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "bayes_cv_scores = cross_val_score(KNeighborsClassifier(n_neighbors=3), x_test, y_test, scoring='precision', cv=10)  \n",
    "bayes_cv_mean = np.mean(bayes_cv_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>cv_precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Logistic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>d.Tree</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>r.f.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>SVM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.979798</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>kNN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Bayes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy        F1     Model  Precision  cv_precision    recall\n",
       "0  1.000000  1.000000  Logistic        1.0          1.00  1.000000\n",
       "1  1.000000  1.000000    d.Tree        1.0          1.00  1.000000\n",
       "2  1.000000  1.000000      r.f.        1.0          1.00  1.000000\n",
       "3  0.989899  0.985507       SVM        1.0          1.00  0.971429\n",
       "4  0.979798  0.970588       kNN        1.0          0.95  0.942857\n",
       "5  1.000000  1.000000     Bayes        1.0          0.95  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model comparison\n",
    "models = pd.DataFrame({  \n",
    "  'Model': ['Logistic', 'd.Tree', 'r.f.', 'SVM', 'kNN',  'Bayes'],\n",
    "  'Accuracy' : [logit_accuracy, tree_accuracy, rf_accuracy, svm_accuracy, knn_accuracy, bayes_accuracy],\n",
    "  'Precision': [logit_precision, tree_precision, rf_precision, svm_precision, knn_precision, bayes_precision],\n",
    "  'recall' : [logit_recall, tree_recall, rf_recall, svm_recall, knn_recall, bayes_recall],\n",
    "  'F1' : [logit_f1, tree_f1, rf_f1, svm_f1, knn_f1, bayes_f1],\n",
    "  'cv_precision' : [logit_cv_mean, tree_cv_mean, rf_cv_mean, svm_cv_mean, knn_cv_mean, bayes_cv_mean]\n",
    "})\n",
    "# Print table and sort by test precision\n",
    "models.sort_values(by='Precision', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save reduced dataset (insert project token from settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'project' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-05f4992e1c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_not_to_keep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset2.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'project' is not defined"
     ]
    }
   ],
   "source": [
    "all_columns = df.columns.tolist()\n",
    "columns_to_keep = ['web_traffic', 'sslfinal_state', 'age_of_domain', 'url_of_anchor', 'domain_registation_length', 'redirect', 'links_in_tags', 'target']\n",
    "columns_not_to_keep = [cols for cols in all_columns if cols not in columns_to_keep]\n",
    "df1 = df.drop(columns_not_to_keep, axis=1)\n",
    "\n",
    "project.save_data(data=df1.to_csv(index=False),file_name='dataset2.csv',overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
